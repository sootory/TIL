# 세미프로젝트
## 자연어처리(NLP) 이론 심화_4장 단어 수준 임베딩(2)
1. GloVe
 - 단어 간 유사도를 측정하기 어렵다는 잠재 의미 분석의 단점과 말뭉치 전체의 통계 정보는 반영되기 어렵다는 Word2Vec의 단점을 극복하고자 한 기법
 - 목적함수는 임베딩된 두 단어 벡터의 내적이 말뭉치 전체에서의 동시 등장 빈도의 로그 값으로 정의됨. 각 단어의 벡터 사이의 내적 값과 두 단어 동시 등장 빈도의 로그 값의 차이가 최소화될수록 학습 손실이 작아짐
 - 말뭉치를 대상으로 단어-문맥 행렬을 만드는 것에서부터 학습을 시작한 후, 목적함수를 최소화하는 임베딩 벡터를 찾기 위한 행렬 분해를 수행

2. Swivel
 - 타깃 단어와 문맥 단어가 같이 자주 등장할수록 두 단어에 해당하는 벡터의 내적이 PMI값과 일치하도록 더 강제함
 - 특정 윈도우 내에서 타깃과 문맥 단어가 동시에 등장한 적이 한번도 없을 때는 별도의 목적함수 가 있음. 두 단어의 동시 등장 횟수를 0이 아닌 1로 가정하고 PMI값 계산
 - 예를 들어, 두 단어가 모두 고빈도 단어인데 동시 등장 빈도가 0이라면 의미상 무관한 단어일 것이라고 가정하지만 저빈도 단어인데 두 단어의 동시 등장 빈도가 없다면 의미상 관계가 일부 있을 수 있다고 봄

3. 어떤 단어 임베딩을 사용할 것인가
 - 단어 임베딩을 평가하는 방법에는 크게 단어 유사도 평가와 단어 유추 평가가 있음
 - Word2Vec, FastText, GloVe, Swivel 네 종류가 포함되어 있는 이미 학습된 단어 임베딩을 다운로드하여 평가해봄
 - 먼저, 단어 유사도 평가는 일련의 단어 쌍을 미리 구성한 후 사람이 평가한 유사도 점수와 단어 벡터 간 코사인 유사도 사이의 상관관계를 계산해 임베딩 품질을 평가함. 평가 실행 결과, Word2Vec과 FastText 같은 예측 기반 기법들이 Glove, Swivel과 같은 행렬 분해 방법보다 성능이 낫다고 볼 수 있었음
 - 단어 유추 평가는 단어 벡터 간 계산을 통해 특정 단어 질의("갑-을+병")에 의미론적 단어("정")를 도출해낼 수 있는지 평가하는 것으로, "갑-을+병"에 해당하는 벡터에 대해 코사인 유사도가 가장 높은 벡터의 단어가 "정"인지 확인함
 - 해당 교재에서 위의 4가지 기법으로 단어 유추 평가를 실행했을 때는 Word2Vec과 Glove가 상대적으로 좋은 성능을 나타냄 


참고 자료: [도서] 한국어 임베딩, 딥러닝을 이용한 자연어 처리 입문   
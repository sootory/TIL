# 자습
## 딥러닝 이론 정리
1. 신경망
- 신경망은 입력층, 은닉층, 출력증으로 구성
- 출력층의 활성화 함수는 회귀는 항등 함수, 분류에는 시그모이드 함수, 다중 클래스 분류에는 소프트맥스 함수를 사용하는 것이 일반적
- 분류 문제에서의 출력층의 뉴런 수는 분류하고 싶은 클래스의 수로 설정하는 것이 일반적임
  
2. 신경망 학습
- 학습이란 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것을 뜻함
- 손실 함수의 값을 가장 적게 만드는 가중치 매개변수를 찾는 것이 학습의 목표임
- 기계학습은 데이터 주도 학습을 수행함. 신경망과 딥러닝은 기존 기계학습보다 더 사람의 개입을 줄임
- 예를 들어, 숫자를 인식하는 알고리즘을 구현할 때 이미지에서 특징(feature)을 추출하고 그 특징의 패턴을 기계학습 기술로 학습하는 방법이 있음. 이때, 이미지를 벡터로 변화할 떄 사용하는 특징은 여전히 사람이 설계해야 하지만 신경망(딥러닝) 방식은 이미지를 있는 그대로 학습함(특징까지 기계가 스스로 학습)
- 기계학습에서는 훈련 데이터(training data)와 시험 데이터(test data)로 나눠 수행. 훈련 데이터만을 통해 최적의 매개변수를 찾고, 시험 데이터를 사용하여 훈련한 모델의 실력을 평가함
- 한 데이터 셋에만 지나치게 최적화된 상태를 오버피팅(overfitting)이라고 함
- 신경망 학습에서 사용하는 지표는 손실 함수인데, 대체로 오차제곱합과 교차 엔트로피 오차를 사용함
- 훈련 데이터로부터 일부만 골라 학습을 수행하는 것을 미니배치 학습이라고 함
- 신경망의 학습지표로 정확도 대신 손실함수를 쓰는 이유는 정확도를 지표로 하면 매개변수의 미분이 대부분의 장소에서 0이 되기 때문
- 경사법은 현 위치에서 기울어진 방향으로 이동하며 손실함수의 값을 점차 줄여가는 것을 의미
- 학습률은 한번에 얼만큼 학습할지(매개변수의 값을 어마나 갱신할지를 정하는) 정하는 것을 뜻함. 학습률과 같은 매개변수를 하이퍼 파라미터라고 하는데 가중치 매개변수와 달리 사람이 직접 설정해야 하는 특징이 있음
- 신경망에서의 기울기란 가중치 매개변수에 대한 손실함수의 기울기

참고 자료: [도서] 밑바닥부터 시작하는 딥러닝